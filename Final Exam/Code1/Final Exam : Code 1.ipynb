{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Exam : Code 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAUkOAterzQNP5VbQfROba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muchlisam17/Machine-Learning-Task-TelU/blob/main/Final%20Exam/Code1/Final%20Exam%20%3A%20Code%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/MnistSimpleCNN-master.zip\n",
        "#meng-unzip file MnistSimpleCNN-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SATLqoNZt86d",
        "outputId": "9ffd828f-1561-4c52-b383-5405249e3db5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/MnistSimpleCNN-master.zip\n",
            "3a13cdb79c633c96384318f6c2b634179ce3d191\n",
            "   creating: MnistSimpleCNN-master/\n",
            "  inflating: MnistSimpleCNN-master/README.md  \n",
            "   creating: MnistSimpleCNN-master/code/\n",
            "   creating: MnistSimpleCNN-master/code/__pycache__/\n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/augment.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/ema.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/ema.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/mnist.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/models.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/models.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/transforms.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/__pycache__/transforms.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/datasets.py  \n",
            "  inflating: MnistSimpleCNN-master/code/ema.py  \n",
            "  inflating: MnistSimpleCNN-master/code/ensemble.py  \n",
            "  inflating: MnistSimpleCNN-master/code/homo_ensemble.py  \n",
            "   creating: MnistSimpleCNN-master/code/models/\n",
            "   creating: MnistSimpleCNN-master/code/models/__pycache__/\n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/__init__.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp2.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/comp3.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/compa1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/hvc.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/hvc.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/merge.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/merge.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modelM5.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela1.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela1.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela2.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela2.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela3.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela4.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modela4.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/modelh.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/models.cpython-37.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/__pycache__/models.cpython-38.pyc  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM3.py  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM5.py  \n",
            "  inflating: MnistSimpleCNN-master/code/models/modelM7.py  \n",
            "   creating: MnistSimpleCNN-master/code/other_models/\n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp1.py  \n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp2.py  \n",
            "  inflating: MnistSimpleCNN-master/code/other_models/comp3.py  \n",
            "  inflating: MnistSimpleCNN-master/code/test.py  \n",
            "  inflating: MnistSimpleCNN-master/code/train.py  \n",
            "  inflating: MnistSimpleCNN-master/code/transforms.py  \n",
            "   creating: MnistSimpleCNN-master/data/\n",
            "   creating: MnistSimpleCNN-master/data/MNIST/\n",
            "   creating: MnistSimpleCNN-master/data/MNIST/processed/\n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/processed/test.pt  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/processed/training.pt  \n",
            "   creating: MnistSimpleCNN-master/data/MNIST/raw/\n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte.gz  \n",
            "  inflating: MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte  \n",
            " extracting: MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte.gz  \n",
            "   creating: MnistSimpleCNN-master/logs/\n",
            " extracting: MnistSimpleCNN-master/logs/README.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ema.py"
      ],
      "metadata": {
        "id": "09DeXlgMcJJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]\n",
        "\n"
      ],
      "metadata": {
        "id": "lXvZoI6pUC7l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##dataset.py"
      ],
      "metadata": {
        "id": "Tq-RXY_scax8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "0PwI4QxjcVJw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##transforms.py"
      ],
      "metadata": {
        "id": "HeertLTtcibc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torchvision.transforms.functional as TV\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return TV.rotate(img, angle, False, False, None, None)\n"
      ],
      "metadata": {
        "id": "eX6t1LLxcVCe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##modelM3.py"
      ],
      "metadata": {
        "id": "kVRnZ7gccyEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "GgxBo8Vocx_T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##modelM5.py"
      ],
      "metadata": {
        "id": "6hj0dRB2c0r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "66P1N_voc0r4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##modelM7.py"
      ],
      "metadata": {
        "id": "YRlocGwZc0yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ],
      "metadata": {
        "id": "6cCUTn24c0yK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##train.py"
      ],
      "metadata": {
        "id": "hLkXxuXPdZUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports -------------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed ------------------------------------------------#\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size of model --------------------------------------------------------#\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # number of epochs ------------------------------------------------------------#\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # file names ------------------------------------------------------------------#\n",
        "    if not os.path.exists(\"/content/MnistSimpleCNN-master/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/MnistSimpleCNN-master/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/MnistSimpleCNN-master/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods ---------------------------------------------------#\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection ----------------------------------------------------#\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # delete result file ----------------------------------------------------------#\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # global variables ------------------------------------------------------------#\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # training and evaluation loop ------------------------------------------------#\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # train process                                                            #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # test process                                                             #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # output                                                                   #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # update learning rate scheduler                                           #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        lr_scheduler.step()\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) #input seeds value\n",
        "p_epoch = int(input (\"Epoch: \")) #input epoch value in each trial\n",
        "p_trials = int(input (\"Trials: \")) #input trial value]\n",
        "p_kernel_size = int(input (\"Kernel size: \")) #input size kernel\n",
        "p_gpu = int(input (\"GPU: \")) #input GPU value\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials):\n",
        "\trun(p_seed + x, p_epoch, p_kernel_size, p_logdir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz5MouZFckAu",
        "outputId": "2f195976-819b-413a-e8c6-52f77d3001ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 17\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "GPU: 0\n",
            "Logdir: modelM5\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.835055\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.672545\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.446485\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381814\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.333888\n",
            "Best accuracy! correct images:  9892\n",
            "\n",
            "Test set: Average loss: 0.1459, Accuracy: 9892/10000 (98.92%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.322609\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.246928\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257343\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.147037\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.212519\n",
            "\n",
            "Test set: Average loss: 0.1495, Accuracy: 9817/10000 (98.17%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.106649\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.104282\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.138825\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.153324\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.101405\n",
            "Best accuracy! correct images:  9938\n",
            "\n",
            "Test set: Average loss: 0.0524, Accuracy: 9938/10000 (99.38%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.070126\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.088854\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.081230\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.114229\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.107765\n",
            "\n",
            "Test set: Average loss: 0.0491, Accuracy: 9921/10000 (99.21%) (best: 99.38%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.101666\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.060720\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.114014\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.111087\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.067609\n",
            "Best accuracy! correct images:  9950\n",
            "\n",
            "Test set: Average loss: 0.0364, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.151514\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.107427\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.064100\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.056299\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.092642\n",
            "\n",
            "Test set: Average loss: 0.0736, Accuracy: 9856/10000 (98.56%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.082799\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.098478\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.064496\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.066305\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.050288\n",
            "\n",
            "Test set: Average loss: 0.0373, Accuracy: 9941/10000 (99.41%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.105161\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.130052\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.087513\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.039375\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.100055\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.068564\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.024884\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.039851\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.044493\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.040405\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9931/10000 (99.31%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.020310\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.078444\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.027345\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.029373\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.037572\n",
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9947/10000 (99.47%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.079635\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.051125\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.032655\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.020478\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.056066\n",
            "\n",
            "Test set: Average loss: 0.0279, Accuracy: 9945/10000 (99.45%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.040044\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.061428\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.014397\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.075863\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.022115\n",
            "\n",
            "Test set: Average loss: 0.0242, Accuracy: 9935/10000 (99.35%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.043887\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.024964\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.036273\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.071108\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.029519\n",
            "\n",
            "Test set: Average loss: 0.0440, Accuracy: 9890/10000 (98.90%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.049499\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.008559\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.018045\n",
            "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.032540\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.062315\n",
            "\n",
            "Test set: Average loss: 0.0265, Accuracy: 9935/10000 (99.35%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 14 [00000/60000 (0%)]\tLoss: 0.021091\n",
            "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.027062\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.027870\n",
            "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.024123\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.085846\n",
            "\n",
            "Test set: Average loss: 0.0213, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 15 [00000/60000 (0%)]\tLoss: 0.030643\n",
            "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.018423\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.028432\n",
            "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.023956\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.020655\n",
            "\n",
            "Test set: Average loss: 0.0248, Accuracy: 9939/10000 (99.39%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 16 [00000/60000 (0%)]\tLoss: 0.007968\n",
            "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.022031\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.021269\n",
            "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.048039\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.016232\n",
            "\n",
            "Test set: Average loss: 0.0268, Accuracy: 9932/10000 (99.32%) (best: 99.50%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.773786\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.613684\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.504440\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.368925\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.293218\n",
            "Best accuracy! correct images:  9885\n",
            "\n",
            "Test set: Average loss: 0.1281, Accuracy: 9885/10000 (98.85%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.225022\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.228377\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.178184\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.223749\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.160537\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.1076, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.135640\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.130890\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.089400\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.150468\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.139404\n",
            "Best accuracy! correct images:  9929\n",
            "\n",
            "Test set: Average loss: 0.0589, Accuracy: 9929/10000 (99.29%) (best: 99.29%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.127142\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.140470\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.086391\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091325\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.111024\n",
            "Best accuracy! correct images:  9946\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 9946/10000 (99.46%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.138204\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.062391\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.051429\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.126736\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.108055\n",
            "\n",
            "Test set: Average loss: 0.0545, Accuracy: 9910/10000 (99.10%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.082040\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.052729\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.057406\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.085831\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.102262\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 9937/10000 (99.37%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.132103\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.111938\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.049627\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.105092\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.035924\n",
            "Best accuracy! correct images:  9954\n",
            "\n",
            "Test set: Average loss: 0.0289, Accuracy: 9954/10000 (99.54%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.036588\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.044361\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.073076\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.055444\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.031396\n",
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9932/10000 (99.32%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.072733\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.050246\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.049310\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.068907\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.053737\n",
            "\n",
            "Test set: Average loss: 0.0439, Accuracy: 9903/10000 (99.03%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.082322\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.064633\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.052153\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.036014\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.021966\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9946/10000 (99.46%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.085052\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.023673\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.100098\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.024028\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.062183\n",
            "\n",
            "Test set: Average loss: 0.0228, Accuracy: 9953/10000 (99.53%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.019583\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.039975\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.017607\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.028906\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.025182\n",
            "Best accuracy! correct images:  9956\n",
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9956/10000 (99.56%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.052245\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.040968\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.072735\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.031625\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.027220\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 9918/10000 (99.18%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.016691\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.058192\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.057398\n",
            "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.067027\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.030174\n",
            "Best accuracy! correct images:  9957\n",
            "\n",
            "Test set: Average loss: 0.0177, Accuracy: 9957/10000 (99.57%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 14 [00000/60000 (0%)]\tLoss: 0.039667\n",
            "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.119804\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.032080\n",
            "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.009757\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.081626\n",
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9925/10000 (99.25%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 15 [00000/60000 (0%)]\tLoss: 0.050498\n",
            "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.016843\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.080705\n",
            "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.016364\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.022987\n",
            "\n",
            "Test set: Average loss: 0.0413, Accuracy: 9899/10000 (98.99%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 16 [00000/60000 (0%)]\tLoss: 0.023378\n",
            "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.038409\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.021334\n",
            "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.028030\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.072815\n",
            "\n",
            "Test set: Average loss: 0.0172, Accuracy: 9954/10000 (99.54%) (best: 99.57%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.534251\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.655485\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.418252\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.396349\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.302562\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1358, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.275565\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.157069\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.266565\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.225049\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.127945\n",
            "Best accuracy! correct images:  9924\n",
            "\n",
            "Test set: Average loss: 0.0775, Accuracy: 9924/10000 (99.24%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.159125\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.104717\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.133520\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.104508\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.093190\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0463, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.112500\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.108116\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.072373\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.119902\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.096861\n",
            "\n",
            "Test set: Average loss: 0.0607, Accuracy: 9904/10000 (99.04%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.048279\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.062117\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.147288\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.061269\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.075314\n",
            "\n",
            "Test set: Average loss: 0.2292, Accuracy: 9258/10000 (92.58%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.090208\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.062100\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.163507\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.092583\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.050434\n",
            "\n",
            "Test set: Average loss: 0.0320, Accuracy: 9927/10000 (99.27%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.054386\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.083772\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.094434\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.038730\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.057275\n",
            "Best accuracy! correct images:  9946\n",
            "\n",
            "Test set: Average loss: 0.0304, Accuracy: 9946/10000 (99.46%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.021373\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.043372\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.042333\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.056503\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.016980\n",
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 9939/10000 (99.39%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.163931\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.077440\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.086991\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.037188\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.047283\n",
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 9936/10000 (99.36%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.221978\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.048218\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.070188\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.024978\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.067160\n",
            "\n",
            "Test set: Average loss: 0.0254, Accuracy: 9945/10000 (99.45%) (best: 99.46%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.022722\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.035161\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.018463\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.012344\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.034606\n",
            "Best accuracy! correct images:  9959\n",
            "\n",
            "Test set: Average loss: 0.0207, Accuracy: 9959/10000 (99.59%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.013728\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.087413\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.020972\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.074051\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.016593\n",
            "\n",
            "Test set: Average loss: 0.0280, Accuracy: 9928/10000 (99.28%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.015327\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.039226\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.041901\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.043726\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.032966\n",
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 9944/10000 (99.44%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.060486\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.016109\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.049794\n",
            "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.026504\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.076201\n",
            "\n",
            "Test set: Average loss: 0.0256, Accuracy: 9932/10000 (99.32%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 14 [00000/60000 (0%)]\tLoss: 0.036227\n",
            "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.043483\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.068263\n",
            "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.037054\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.014558\n",
            "\n",
            "Test set: Average loss: 0.0191, Accuracy: 9951/10000 (99.51%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 15 [00000/60000 (0%)]\tLoss: 0.049419\n",
            "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.016118\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.033709\n",
            "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.024958\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.039204\n",
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9930/10000 (99.30%) (best: 99.59%)\n",
            "\n",
            "Train Epoch: 16 [00000/60000 (0%)]\tLoss: 0.018962\n",
            "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.019587\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.021905\n",
            "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.055145\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.035943\n",
            "\n",
            "Test set: Average loss: 0.0180, Accuracy: 9952/10000 (99.52%) (best: 99.59%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.715487\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.598849\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.385839\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.393501\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.222687\n",
            "Best accuracy! correct images:  9877\n",
            "\n",
            "Test set: Average loss: 0.1197, Accuracy: 9877/10000 (98.77%) (best: 98.77%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.250755\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.177847\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.159880\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.119191\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167821\n",
            "Best accuracy! correct images:  9912\n",
            "\n",
            "Test set: Average loss: 0.0726, Accuracy: 9912/10000 (99.12%) (best: 99.12%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.145166\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.159978\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.099546\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.113986\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.166505\n",
            "\n",
            "Test set: Average loss: 0.0725, Accuracy: 9894/10000 (98.94%) (best: 99.12%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.098968\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.100518\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.082005\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.118736\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.103927\n",
            "Best accuracy! correct images:  9928\n",
            "\n",
            "Test set: Average loss: 0.0409, Accuracy: 9928/10000 (99.28%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.078123\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.103936\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.093764\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.065919\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.063685\n",
            "\n",
            "Test set: Average loss: 0.0452, Accuracy: 9908/10000 (99.08%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.050268\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.046732\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.083943\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.074624\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.063223\n",
            "\n",
            "Test set: Average loss: 0.0510, Accuracy: 9916/10000 (99.16%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.079019\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.102871\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.037372\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.061051\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.020808\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0358, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.045934\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.027934\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.106635\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.092039\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.034810\n",
            "Best accuracy! correct images:  9948\n",
            "\n",
            "Test set: Average loss: 0.0249, Accuracy: 9948/10000 (99.48%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.050848\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.055358\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.075419\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.044189\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.026836\n",
            "\n",
            "Test set: Average loss: 0.0323, Accuracy: 9941/10000 (99.41%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.020509\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.029496\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.026565\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.076153\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.065705\n",
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9938/10000 (99.38%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.066946\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.024070\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.040374\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.026788\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.022931\n",
            "\n",
            "Test set: Average loss: 0.0269, Accuracy: 9932/10000 (99.32%) (best: 99.48%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.034195\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.058361\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.053607\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.038928\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.047740\n",
            "Best accuracy! correct images:  9954\n",
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 9954/10000 (99.54%) (best: 99.54%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.024033\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.050025\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.015512\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.068644\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.049265\n",
            "Best accuracy! correct images:  9956\n",
            "\n",
            "Test set: Average loss: 0.0181, Accuracy: 9956/10000 (99.56%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.078303\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.098589\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.070343\n",
            "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.012765\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.040248\n",
            "\n",
            "Test set: Average loss: 0.0286, Accuracy: 9926/10000 (99.26%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 14 [00000/60000 (0%)]\tLoss: 0.025760\n",
            "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.041582\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.018018\n",
            "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.014665\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.054477\n",
            "\n",
            "Test set: Average loss: 0.0214, Accuracy: 9948/10000 (99.48%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 15 [00000/60000 (0%)]\tLoss: 0.009504\n",
            "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.046365\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.049654\n",
            "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.123092\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.013958\n",
            "\n",
            "Test set: Average loss: 0.0255, Accuracy: 9933/10000 (99.33%) (best: 99.56%)\n",
            "\n",
            "Train Epoch: 16 [00000/60000 (0%)]\tLoss: 0.032395\n",
            "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.035015\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.109936\n",
            "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.060566\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.067795\n",
            "Best accuracy! correct images:  9957\n",
            "\n",
            "Test set: Average loss: 0.0169, Accuracy: 9957/10000 (99.57%) (best: 99.57%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.723286\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.652956\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.526345\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.312364\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.320387\n",
            "Best accuracy! correct images:  9888\n",
            "\n",
            "Test set: Average loss: 0.1417, Accuracy: 9888/10000 (98.88%) (best: 98.88%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.232118\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.219850\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.220962\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.205403\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.205781\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0872, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.116369\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.108751\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.139506\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.132314\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.086242\n",
            "Best accuracy! correct images:  9911\n",
            "\n",
            "Test set: Average loss: 0.0636, Accuracy: 9911/10000 (99.11%) (best: 99.11%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.095974\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.155512\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.086647\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.107343\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.053135\n",
            "Best accuracy! correct images:  9914\n",
            "\n",
            "Test set: Average loss: 0.0519, Accuracy: 9914/10000 (99.14%) (best: 99.14%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.123737\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.124605\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.064446\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.102000\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.053370\n",
            "\n",
            "Test set: Average loss: 0.0706, Accuracy: 9887/10000 (98.87%) (best: 99.14%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.126911\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.101624\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.080826\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.056804\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.074974\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0354, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.077253\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.034747\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.070536\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.041714\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.029012\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0352, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.064221\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.046486\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.059803\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.074810\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.083895\n",
            "Best accuracy! correct images:  9957\n",
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9957/10000 (99.57%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.078165\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.079921\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.065581\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.076432\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.046388\n",
            "\n",
            "Test set: Average loss: 0.0380, Accuracy: 9906/10000 (99.06%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.087980\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.030419\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.048343\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.062204\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.050743\n",
            "\n",
            "Test set: Average loss: 0.0277, Accuracy: 9940/10000 (99.40%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.091443\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.040225\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.033480\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.023818\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.078316\n",
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 9911/10000 (99.11%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.024328\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.123141\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.048681\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.026612\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.030877\n",
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9946/10000 (99.46%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.048216\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.022760\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.020308\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.043653\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.065824\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 9941/10000 (99.41%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.053513\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.038875\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.067580\n",
            "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.046335\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.037974\n",
            "Best accuracy! correct images:  9964\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9964/10000 (99.64%) (best: 99.64%)\n",
            "\n",
            "Train Epoch: 14 [00000/60000 (0%)]\tLoss: 0.097688\n",
            "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.011823\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.101505\n",
            "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.081264\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.078075\n",
            "\n",
            "Test set: Average loss: 0.0175, Accuracy: 9956/10000 (99.56%) (best: 99.64%)\n",
            "\n",
            "Train Epoch: 15 [00000/60000 (0%)]\tLoss: 0.038582\n",
            "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.097601\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.047165\n",
            "Train Epoch: 15 [36000/60000 (60%)]\tLoss: 0.077460\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.018885\n",
            "\n",
            "Test set: Average loss: 0.0226, Accuracy: 9949/10000 (99.49%) (best: 99.64%)\n",
            "\n",
            "Train Epoch: 16 [00000/60000 (0%)]\tLoss: 0.019039\n",
            "Train Epoch: 16 [12000/60000 (20%)]\tLoss: 0.027337\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.053212\n",
            "Train Epoch: 16 [36000/60000 (60%)]\tLoss: 0.027615\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.053879\n",
            "\n",
            "Test set: Average loss: 0.0141, Accuracy: 9959/10000 (99.59%) (best: 99.64%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.751879\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.702585\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.476892\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.338829\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.273951\n",
            "Best accuracy! correct images:  9879\n",
            "\n",
            "Test set: Average loss: 0.1521, Accuracy: 9879/10000 (98.79%) (best: 98.79%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.276195\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.288302\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.257404\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.163721\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.157312\n",
            "Best accuracy! correct images:  9927\n",
            "\n",
            "Test set: Average loss: 0.0722, Accuracy: 9927/10000 (99.27%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.145820\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.196976\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.147653\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.089642\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.100429\n",
            "\n",
            "Test set: Average loss: 0.0659, Accuracy: 9923/10000 (99.23%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.104864\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.188275\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.073293\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091839\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.141284\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0564, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.120940\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.073196\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.068399\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.083248\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.111080\n",
            "\n",
            "Test set: Average loss: 0.0504, Accuracy: 9910/10000 (99.10%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.073709\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.079481\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.043734\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.042375\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.110998\n",
            "\n",
            "Test set: Average loss: 0.0383, Accuracy: 9931/10000 (99.31%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.051445\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.050051\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.081705\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.055668\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.051070\n",
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9923/10000 (99.23%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.122927\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.025685\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.046748\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.035008\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.064460\n",
            "\n",
            "Test set: Average loss: 0.0305, Accuracy: 9929/10000 (99.29%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.065223\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.050729\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.047836\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.029951\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.053353\n",
            "\n",
            "Test set: Average loss: 0.1375, Accuracy: 9611/10000 (96.11%) (best: 99.40%)\n",
            "\n",
            "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.027072\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.050575\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.020862\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.084489\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.077846\n",
            "Best accuracy! correct images:  9950\n",
            "\n",
            "Test set: Average loss: 0.0218, Accuracy: 9950/10000 (99.50%) (best: 99.50%)\n",
            "\n",
            "Train Epoch: 10 [00000/60000 (0%)]\tLoss: 0.037654\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.056300\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.019691\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.085485\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.105284\n",
            "Best accuracy! correct images:  9957\n",
            "\n",
            "Test set: Average loss: 0.0224, Accuracy: 9957/10000 (99.57%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 11 [00000/60000 (0%)]\tLoss: 0.028437\n",
            "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.046991\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.049212\n",
            "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.034371\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.033078\n",
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9955/10000 (99.55%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 12 [00000/60000 (0%)]\tLoss: 0.035157\n",
            "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.078452\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.076994\n",
            "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.022865\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.111482\n",
            "\n",
            "Test set: Average loss: 0.0347, Accuracy: 9918/10000 (99.18%) (best: 99.57%)\n",
            "\n",
            "Train Epoch: 13 [00000/60000 (0%)]\tLoss: 0.022052\n",
            "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.057883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##test.py"
      ],
      "metadata": {
        "id": "ZOVbwqvldc3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports ---------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"/content/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,p_seed)))\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"/content/MnistSimpleCNN-master/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) #input seeds value\n",
        "p_trials = int(input (\"Trials: \")) #input trial value]\n",
        "p_kernel_size = int(input (\"Kernel size: \")) #input size kernel\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "\n",
        "for x in range (p_trials):\n",
        "\trun(p_seed + x, p_kernel_size, p_logdir)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fF6-dOfNddAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##homo_ensemble.py"
      ],
      "metadata": {
        "id": "3RKrNwEfdoYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int(input (\"Kernel size: \")) #input size kernel\n",
        "KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(i+1,10):\n",
        "        for k in range(j+1,10):\n",
        "            w1 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1\n"
      ],
      "metadata": {
        "id": "qg6nhQ20doR1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}